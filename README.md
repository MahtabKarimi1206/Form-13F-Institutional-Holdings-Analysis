# Form-13F-Institutional-Holdings-Analysis

In this repo, I extract data from 13F filings using the EDGAR API and save them into a PostgreSQL database managed with pgAdmin.

üìèWho are institutional investors?

Institutional investors are large entities that invest significant amounts of money on behalf of their clients. 
Examples include hedge funds and pension funds. ‚óº

üìèWhat is form 13F filing? 

 Since 1978, institutional investment managers‚Äîincluding hedge funds‚Äîthat exercise investment discretion over accounts with at least $100 million must file Form 13F with the SEC each quarter, within 45 days of quarter-end, as required by Section 13(f) of the Exchange Act. ‚óº

üìèWhere to get institutional investor data?

EDGAR provides an API to access these filings, which include data on filing companies and their holdings. The filing company is the institutional investor, and the holdings are the companies whose stocks they own.

‚ñ∑What is the structure of the data? 
      I save the API data in two main tables: one for filings and one for holdings. These tables can be joined using filing_id:
  
      ```
      | Filings table            |
      |--------------------------|
      | filing_id (PRIMARY KEY)  |
      | cik                      |
      | filer_name               |
      | period_of_report (date)  |

      ```
       ```
      | Holdings table    |
      |------------------ |
      | filing_id         |
      | name_of_issuer    |
      | cusip             |
      | cik               |
      | title_of_class    |
      | value             |
      | shares            |
      | put_call          |
      ```

 üìèHow to get the institutional investors data? 

 One straightforward way is to write Python code to retrieve the data (in JSON format) and then save it in a CSV file. The problem is that the volume of this data can be very large and consume a lot of RAM when used later in other scripts. To handle this, I use a PostgreSQL database to retrieve and store the data. This also allows me to leverage SQL tools to work with it more efficiently.  ‚óº

 üìèWhat do I do in this repo to get this data? 
 
As mentioned earlier, I use Python, PostgreSQL, and the EDGAR API to retrieve and store the data in an efficient and reusable way.
In general, I follow two steps:

‚ñ®Set up and implement a PostgreSQL server.

‚ñ®Use Python to retrieve the data from the API and save it into the database.
The picture below shows a schematic of the overall process:

![Process Diagram](images/General_View.png)

 
 ‚ñ®Set up and implement a PostgreSQL server: 
 
 I use pgAdmin to connect to the PostgreSQL database. There are other ways to do this, but since I already had pgAdmin installed on my PC, I chose this approach.

 I assume you already have PostgreSQL and pgAdmin installed on your system. Open pgAdmin and, on the left side, create a new server with any name you like (I named mine Edgar). The server should point to      localhost and use the password you set up during installation.

 ‚ñ®Establish a connection between the SQL server and Jupyter Notebook (Python):  
 
 ```python
import os
import psycopg2
from psycopg2.extras import execute_batch

conn = psycopg2.connect(
    host="localhost",    # database server address (localhost means same machine)
    port=5432,              # default PostgreSQL port 
    dbname="sec13f",         # name of the database to connect to
    user="postgres",            # username for authentication
    password="****"        # password (this is the data base password)
)

# Disable autocommit so changes must be committed manually
conn.autocommit = False

# Create a cursor object to execute SQL queries
cur = conn.cursor()
```
In this part, just to make sure we are connected to our database, I run the following code to establish a connection, retrieve some data, and then close the connection.

```python
# create a cursor
cur = conn.cursor()

# execute a statement
cur.execute('SELECT version()')

# display the PostgreSQL database server version
db_version = cur.fetchone()

print('PostgreSQL database version:')
print(db_version)

# close the communication with the PostgreSQL
cur.close()
```
The result should look something like this:

```python
PostgreSQL database version:
('PostgreSQL 17.4 on x86_64-windows, compiled by msvc-19.42.34436, 64-bit',)
```

Now that we have confirmed we can properly connect to our database through Python, we can start adding tables to it.
The database has three main tables:

1- table of all filing investors.

2- A table of all holdings ‚Äî these are the firms in which the filing investors hold stock.

3- A table mapping the IDs of filing investors to the IDs of investors. I will not use this table because the mappings generated by EDGAR lack a time frame and are therefore not reliable. Instead, I will use WRDS tables.

Of course, we could create these tables in PgAdmin using SQL queries, but for now, I am focusing on creating them in Python using the table function below.

```python
def create_tables():

     # Create a cursor object to interact with the database
    cur = conn.cursor()

    # Define SQL commands to create the necessary tables
    create_table_commands = (
        # Table to store information about each filing
        """
            CREATE TABLE filings (
                filing_id varchar(255) PRIMARY KEY,    -- unique identifier for each filing
                cik int,                                -- central index key of the filer
                filer_name varchar(255),                -- name of the filer
                period_of_report date                   -- reporting period
            )
        """,
        """
            CREATE TABLE holdings (
                filing_id varchar(255),                  -- reference to the filing ID
                name_of_issuer varchar(255),             -- name of the issuer of the security
                cusip varchar(255),                      -- CUSIP identifier of the security
                cik text,                                -- CIK of the issuer
                title_of_class varchar(255),             -- class of the security
                value bigint,                            -- value of the holding
                shares int,                               -- value of the holding  
                put_call varchar(255)                    -- option type, if applicable
            )
        """, 
        """
            CREATE TABLE holding_infos (
                cusip varchar(255),                         -- CUSIP identifier (link to holdings table)                  
                security_name varchar(255),                 -- name of the security
                ticker varchar(50),                         -- ticker symbol
                exchange_code varchar(10),                  -- exchange code 
                security_type varchar(50)                   -- type of security (e.g., stock, bond) 
            )
        """)

    # create table one by one
    for command in create_table_commands:
        cur.execute(command)
    
    # close cursor
    cur.close()
    
    # make the changes to the database persistent
    conn.commit()
```
If you call the function using create_tables() and then go to your PgAdmin database interface for the related server, refresh the tables section. You should see three tables ‚Äî filings, holdings, and holding_infos ‚Äî with the columns defined above. However, the point is that all the tables are empty ‚Äî they only contain the column names. To fill them, I connect to the EDGAR API to retrieve the data and then insert it into the corresponding columns defined above.

The first step is to connect to the EDGAR API. To do this, you need an API key, which you can obtain at https://sec-api.io. Then, import the sec_api module in Python. Next, write a query to connect to the API and retrieve the data in Python.
